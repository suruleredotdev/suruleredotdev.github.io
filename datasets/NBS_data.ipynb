{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.0.0-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting geographiclib<2,>=1.49\n",
      "  Downloading geographiclib-1.50-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-1.50 geopy-2.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_xls = xlrd.open_workbook(\"nbs-state-commodity-costs-data/selected_food_august_2020.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABIA',\n",
       " 'ABUJA',\n",
       " 'ANAMBRA',\n",
       " 'EBONYI',\n",
       " 'ENUGU',\n",
       " 'IMO',\n",
       " 'AKWA IBOM',\n",
       " 'BAYELSA',\n",
       " 'CROSS RIVER',\n",
       " 'DELTA',\n",
       " 'RIVERS',\n",
       " 'EDO',\n",
       " 'ADAMAWA',\n",
       " 'BAUCHI',\n",
       " 'BORNO',\n",
       " 'GOMBE',\n",
       " 'TARABA',\n",
       " 'YOBE',\n",
       " 'BENUE',\n",
       " 'KOGI',\n",
       " 'KWARA',\n",
       " 'NASSARAWA',\n",
       " 'NIGER',\n",
       " 'PLATEAU',\n",
       " 'EKITI',\n",
       " 'LAGOS',\n",
       " 'ONDO',\n",
       " 'OGUN ',\n",
       " 'OSUN',\n",
       " 'OYO',\n",
       " 'JIGAWA ',\n",
       " 'KADUNA ',\n",
       " 'KANO ',\n",
       " 'KATSINA',\n",
       " 'KEBBI ',\n",
       " 'ZAMFARA ',\n",
       " 'SOKOTO',\n",
       " 'NATIONAL']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_xls.sheet_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES = [\n",
    "    \"Abia\",\n",
    "    \"Adamawa\",\n",
    "    \"Akwa Ibom\",\n",
    "    \"Anambra\",\n",
    "    \"Bauchi\",\n",
    "    \"Bayelsa\",\n",
    "    \"Benue\",\n",
    "    \"Borno\",\n",
    "    \"Cross River\",\n",
    "    \"Delta\",\n",
    "    \"Ebonyi\",\n",
    "    \"Edo\",\n",
    "    \"Ekiti\",\n",
    "    \"Enugu\",\n",
    "    \"Gombe\",\n",
    "    \"Imo\",\n",
    "    \"Jigawa\",\n",
    "    \"Kaduna\",\n",
    "    \"Kano\",\n",
    "    \"Katsina\",\n",
    "    \"Kebbi\",\n",
    "    \"Kogi\",\n",
    "    \"Kwara\",\n",
    "    \"Lagos\",\n",
    "    \"Nasarawa\",\n",
    "    \"Niger\",\n",
    "    \"Ogun\",\n",
    "    \"Ondo\",\n",
    "    \"Osun\",\n",
    "    \"Oyo\",\n",
    "    \"Plateau\",\n",
    "    \"Rivers\",\n",
    "    \"Sokoto\",\n",
    "    \"Taraba\",\n",
    "    \"Yobe\",\n",
    "    \"Zamfara\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ([x.upper() for x in STATES]).sort() == ([x.strip() for x in example_xls.sheet_names()]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def csv_from_excel(filename):\n",
    "    wb = xlrd.open_workbook(filename)\n",
    "    for sheet in wb.sheet_names():\n",
    "        sh = wb.sheet_by_name(sheet)\n",
    "        wb_name = os.path.splitext(filename)[0]\n",
    "        csv_file = open(wb_name.strip() + \"_\" + sheet.strip() + '.csv', 'w')\n",
    "        wr = csv.writer(csv_file, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "        start_writing = False\n",
    "        for rownum in range(sh.nrows):\n",
    "            row_values = sh.row_values(rownum)[:-2] # trim off aggregate MoM and YoY values (for now)\n",
    "            # convert date values on header row of data\n",
    "            if row_values[0] == \"ItemLabels\":\n",
    "                # don't start writing to the sheet till \"ItemLabels\" row\n",
    "                # b/c some of the data files have padding rows at the top that aren't needed\n",
    "                start_writing = True \n",
    "                # print(row_values[1:])\n",
    "                date_values = [xlrd.xldate.xldate_as_datetime(val, wb.datemode).strftime(\"%b %Y\") for val in row_values[1:] if isinstance(val, float)]\n",
    "                # print(date_values)\n",
    "                row_values[1:len(date_values)+1] = date_values\n",
    "            if start_writing: wr.writerow(row_values)\n",
    "\n",
    "        csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def joint_csv_from_excel(filename):\n",
    "    wb = xlrd.open_workbook(filename)\n",
    "    wb_name = os.path.splitext(filename)[0]\n",
    "    csv_file = open(wb_name.strip() + \"___JOINED.csv\", 'w')\n",
    "    wr = csv.writer(csv_file, quoting=csv.QUOTE_ALL)\n",
    "    for sheet in wb.sheet_names():\n",
    "        sh = wb.sheet_by_name(sheet)\n",
    "                \n",
    "        start_writing = False\n",
    "        for rownum in range(sh.nrows):\n",
    "            row_values = sh.row_values(rownum)[:-2] # trim off aggregate MoM and YoY values (for now)\n",
    "            \n",
    "            # convert date values on header row of data\n",
    "            if row_values[0] == \"ItemLabels\":\n",
    "                if rownum > 0: continue # only acknowledge header row on first sheet\n",
    "                # don't start writing to the sheet till \"ItemLabels\" row\n",
    "                # b/c some of the data files have padding rows at the top that aren't needed\n",
    "                start_writing = True \n",
    "                # print(row_values[1:])\n",
    "                date_values = [xlrd.xldate.xldate_as_datetime(val, wb.datemode).strftime(\"%b %Y\") for val in row_values[1:] if isinstance(val, float)]\n",
    "                # print(date_values)\n",
    "                row_values[1:len(date_values)+1] = date_values\n",
    "            \n",
    "            row_values.insert(0, sheet) # insert name of state (corresponding to sheet in source .xlsx) to start of row\n",
    "            \n",
    "            if start_writing: wr.writerow(row_values)\n",
    "\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_from_excel(\"nbs-state-commodity-costs-data/selected_food_august_2020.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_from_excel(\"nbs-state-commodity-costs-data/transport_cost_august_2020.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above commands ([In 55]) and ([In 16]) should have created a new CSV in the same directory corresponding to each data-sheet with statistics for individual states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_csv_from_excel(\"nbs-state-commodity-costs-data/selected_food_august_2020.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above command ([In 8]) should have created a new CSV containing the conglomerated data for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geojson import Feature, FeatureCollection, Point\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_features_from_csv(filename):\n",
    "    features = []\n",
    "    geocode_map = {}\n",
    "    feature_map = {}\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        headers = next(reader)\n",
    "        headers[0] = \"State\"\n",
    "        geolocator = Nominatim(user_agent=\"nbs_state_commodity_costs_ipynb\")\n",
    "        for row in reader:\n",
    "            location_name = row[0]\n",
    "            location, latitude, longitude = None, None, None \n",
    "            if location_name not in geocode_map:\n",
    "                print(\"Looking up location: \", location_name)\n",
    "                location = geolocator.geocode(location_name + \", Nigeria\");\n",
    "                print(\"\\t (long, lat): (%f, %f)\" % (location.longitude, location.latitude))\n",
    "                # print(\"\\t (long, lat): (%f, %f) \\n\\t bounds: %s\" % (location.longitude, location.latitude, ', '.join(map(str, location.bounds))))\n",
    "                geocode_map[location_name] = location\n",
    "            else:\n",
    "                location = geocode_map[location_name]\n",
    "            latitude, longitude = map(float, (location.latitude, location.longitude))\n",
    "            if location_name not in geocode_map:\n",
    "                feature_map[location_name]\n",
    "            features.append(\n",
    "                Feature(\n",
    "                    geometry = Point((longitude, latitude)),\n",
    "                    properties = { headers[i]: row[i] for i in range(1, len(headers)) }\n",
    "                )\n",
    "            )\n",
    "        csvfile.close()\n",
    "    features = [ v for k, v in feature_map ]\n",
    "\n",
    "    collection = FeatureCollection(features)\n",
    "    with open(\"nbs-state-commodity-costs-data.json\", \"w\") as f:\n",
    "        f.write('%s' % collection)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up location:  ABIA\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Location' object has no attribute 'bounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b3c5ef3dd187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgeojson_features_from_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nbs-state-commodity-costs-data/selected_food_august_2020___JOINED.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-8453dbff9d0e>\u001b[0m in \u001b[0;36mgeojson_features_from_csv\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Looking up location: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Nigeria\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t (long, lat): (%f, %f) \\n\\y bounds: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mgeocode_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Location' object has no attribute 'bounds'"
     ]
    }
   ],
   "source": [
    "geojson_features_from_csv(\"nbs-state-commodity-costs-data/selected_food_august_2020___JOINED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
